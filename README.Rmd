---
output: 
  github_document: 
    pandoc_args: --webtex=https://render.githubusercontent.com/render/math?math=
bibliography: ref.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  cache.path = "cache/README-",
  out.width = "100%", fig.width = 7, fig.height = 4,
  message = FALSE, warning = FALSE, error = FALSE)
options(digits = 4)
```

# pedmod: Pedigree Models

[![R-CMD-check](https://github.com/boennecd/pedmod/workflows/R-CMD-check/badge.svg)](https://github.com/boennecd/pedmod/actions)

The pedmod package provides functions to estimate models for pedigree data. 
Particularly, the package provides functions to estimate mixed models of 
the form:

$$\begin{align*}
Y_{ij} \mid \epsilon_{ij} = e 
  &\sim \text{Bin}(\Phi(\vec\beta^\top\vec x_{ij} + e), 1) \\
\vec\epsilon_i = (\epsilon_{i1}, \dots, \epsilon_{in_i})^\top &\sim
  N^{(n_i)}\left(\vec 0, \sum_{l = 1}^K\sigma_l^2 C_{il}
  \right)
\end{align*}$$

where $Y_{ij}$ is the binary outcome of interest for individual $j$ in 
family/cluster $i$, $\vec x_{ij}$ is the individual's known covariates, 
$\Phi$ is the standard normal distribution's CDF, and 
$\text{Bin}$ implies a binomial distribution such if 
$z\sim \text{Bin}(p, n)$ then the density of $z$ is:

$$f(z) = \begin{pmatrix} n \\ z \end{pmatrix}p^zp^{n-z}$$

A different and equivalent way of writing the model is as:

$$\begin{align*}
Y_{ij} \mid \epsilon_{ij} = e 
  &= \begin{cases}
    1 & \vec\beta^\top\vec x_{ij} + e > 0 \\
    0 & \text{otherwise}
    \end{cases} \\
\vec\epsilon_i = (\epsilon_{i1}, \dots, \epsilon_{in_i})^\top &\sim
  N^{(n_i)}\left(\vec 0, I_{n_i} + \sum_{l = 1}^K\sigma_l^2 C_{il}
  \right)
\end{align*}$$

where $I_{n_i}$ is the $n_i$ dimensional identity matrix which comes from the 
unshared/individual specific random effect. This effect is always included. 

The $C_{il}$s are known scale/correlation matrices where each of the $l$'th 
types correspond to a type of effect. An arbitrary number of such matrices can 
be passed to include e.g. a genetic effect, a maternal effect, a paternal, an 
effect of a shared adult environment etc. A 
typical example is that $C_{il}$ is two times the kinship matrix in which 
case we call:

$$\frac{\sigma_l^2}{1 + \sum_{k = 1}^K\sigma_k^2}$$

the heritability (the proportion of the variance attributable to the direct 
genetic effect). 
The scale parameters, the $\sigma_k^2$s, may be the 
primary interest in an analysis. We fix the unshared random effect' 
variance to be one which gives the one in the denominator. Other authors prefer that
the denominator is restricted to be one. Both restriction can be applied to 
ensure identification and they do not have any implications as the scale 
is arbitrary. 

This package provides randomized quasi-Monte Carlo methods to approximate 
the log marginal likelihood for these types of 
models with an arbitrary number scale matrices, $K$, and the derivatives 
with respect to $(\vec\beta^\top, 2\log\sigma_1,\dots, 2\log\sigma_K)^\top$
(that is, we work with $\theta_k = 2\log\sigma_k$).
We have re-written the Fortran code by @Genz02 in C++, made it easy to 
extend from a log marginal likelihood approximation to other approximations 
such as the derivatives, and added less precise but faster approximations 
of the $\Phi$ and $\Phi^{-1}$. Our own experience suggests that using the 
latter has a small effect on the precision of the result but can yield 
substantial reduction in computation times for moderate sized 
families/clusters.

The approximation by @Genz02 have already been used to estimate these 
types of models [@Pawitan04]. However, not having the gradients may slow 
down estimation substantially. Moreover, our implementation supports 
computation in parallel which is a major advantage given the 
availability of multi-core processors. 

Since the implementation is easy to extend, possible extensions are: 

 1. Survival times using mixed generalized survival models [@Liu17] with 
    a similar random effect structure as the model shown above. This way, 
    one avoids dichotomizing outcomes and can account for censoring.
 2. Generalized linear mixed model with binary, binomial, ordinal, or 
    multinomial outcomes with a probit link. The method we use here may be
    beneficial if the number of random effects per cluster is not much 
    smaller then the number observations in each cluster.
    
## Installation
The package can be installed from Github by calling:

```{r how_to_install, eval = FALSE}
remotes::install_github("boennecd/pedmod")
```

## Example

We start with a simple example only with a direct genetic effect. We have one 
type of family which consists of two couples which are related through one 
of the parents being cousins. The family is shown below.

```{r setup_simple}
# create the family we will use
fam <- data.frame(id = 1:10, sex = rep(1:2, 5L),
                  father = c(NA, NA, 1L, NA, 1L, NA, 3L, 3L, 5L, 5L), 
                  mother = c(NA, NA, 2L, NA, 2L, NA, 4L, 4L, 6L, 6L))

# plot the pedigree
library(kinship2)
ped <- with(fam, pedigree(id = id, dadid = father, momid = mother, sex = sex))
plot(ped)
```

We set the scale matrix to be two times the kinship matrix to model the direct
genetic effect. Each individual also have a standard normally distributed 
covariate and a binary covariate. Thus, we can simulate a data set with a 
function like:

```{r assign_sim_dat}
# simulates a data set. 
# 
# Args:
#   n_fams: number of families.
#   beta: the fixed effect coefficients.
#   sig_sq: the scale parameter.
sim_dat <- function(n_fams, beta = c(-3, 1, 2), sig_sq = 3){
  # setup before the simulations
  Cmat <- 2 * kinship(ped)
  n_obs <- NROW(fam)
  Sig <- diag(n_obs) + sig_sq * Cmat
  Sig_chol <- chol(Sig)
  
  # simulate the data
  out <- replicate(
    n_fams, {
      # simulate covariates
      X <- cbind(`(Intercept)` = 1, Continuous = rnorm(n_obs), 
                 Binary = runif(n_obs) > .5)
      
      # assign the linear predictor + noise
      eta <- drop(X %*% beta) + drop(rnorm(n_obs) %*% Sig_chol)
      
      # return the list in the format needed for the package
      list(y = as.numeric(eta > 0), X = X, scale_mats = list(Cmat))
    }, simplify = FALSE)
  
  # add attributes with the true values and return 
  attributes(out) <- list(beta = beta, sig_sq = sig_sq)
  out
}
```

The model is 

$$\begin{align*}
 Y_{ij} &= \begin{cases} 1 & \beta_0 + \beta_1 X_{ij} + \beta_2 B_{ij} + G_{ij} + R_{ij} > 0 \\ 0 & \text{otherwise} \end{cases} \\
 X_{ij} &\sim N(0, 1) \\
 B_{ij} &\sim \text{Bin}(0.5, 1) \\
 (G_{i1}, \dots G_{in_{i}})^\top &\sim N^{(n_i)}(\vec 0, \sigma^2 C_{i1}) \\
 R_{ij} &\sim N(0, 1)\end{align*}$$
 
where $C_{i1}$ is two times the kinship matrix and $X_{ij}$ and 
$B_{ij}$ are observed covariates. We can now estimate the model with a simulated 
data set as follows:

```{r est_simple, cache = 1}
# simulate a data set
set.seed(27107390)
dat <- sim_dat(n_fams = 400L)

# perform the optimization. We start with finding the starting values
library(pedmod)
ll_terms <- get_pedigree_ll_terms(dat, max_threads = 4L)
system.time(start <- pedmod_start(
  ptr = ll_terms, data = dat, n_threads = 4L))

# log-likelihood without the random effects and at the starting values
start$logLik_no_rng
start$logLik_est # this is unreliably/imprecise

# estimate the model
system.time(
  opt_out <- pedmod_opt(
    ptr = ll_terms, par = start$par, abs_eps = 0, use_aprx = TRUE, 
    n_threads = 4L, 
    maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L))
```

The results are shown below:

```{r est_simple_res}
# parameter estimates versus the truth
rbind(opt_out       = head(opt_out$par, -1), 
      opt_out_quick = head(start  $par, -1), 
      truth         = attr(dat, "beta"))
c(opt_out       = exp(tail(opt_out$par, 1)), 
  opt_out_quick = exp(tail(start  $par, 1)), 
  truth         = attr(dat, "sig_sq"))

# log marginal likelihoods
print(start   $logLik_est, digits = 8) # this is unreliably/imprecise
print(-opt_out$value     , digits = 8)
```

We can compute a profile likelihood curve like this:

```{r simple_ex_profile_likelihood, cache = 1}
rg <- range(exp(tail(opt_out$par, 1) / 2) * c(.5, 2),
            sqrt(attr(dat, "sig_sq")) * c(.9, 1.1))
sigs <- seq(rg[1], rg[2], length.out = 10)
sigs <- sort(c(sigs, exp(tail(opt_out$par, 1) / 2)))

ll_terms <- get_pedigree_ll_terms(dat, max_threads = 4L)
pl_curve_res <- lapply(sigs, function(sig){
  # set the parameters to pass
  beta <- start$beta_no_rng
  sig_sq_log <- 2 * log(sig)
  beta_scaled <- beta * sqrt(1 + sig^2)
  
  # optimize like before but using the fix argument
  opt_out_quick <- pedmod_opt(
    ptr = ll_terms, par = c(beta_scaled, sig_sq_log), maxvls = 1000L, 
    abs_eps = 0, rel_eps = 1e-2, minvls = 100L, use_aprx = TRUE, n_threads = 4L, 
    fix = length(beta) + 1L)
  opt_out <- pedmod_opt(
    ptr = ll_terms, par = c(opt_out_quick$par, sig_sq_log), abs_eps = 0, 
    use_aprx = TRUE, n_threads = 4L, fix = length(beta) + 1L,
    # we changed the parameters
    maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L)
  
  # report to console and return
  message(sprintf("\nLog-likelihood %.5f (%.5f). Estimated parameters:", 
                  -opt_out$value, -opt_out_quick$value))
  message(paste0(capture.output(print(
    c(opt_out$par, Scale = sig))), collapse = "\n"))
  
  list(opt_out_quick = opt_out_quick, opt_out = opt_out)
})
```

We can construct an approximate 95% confidence interval using an estimated 
cubic smoothing spline for the profile likelihood (more `sigs` points may be 
needed to get a good estimate of the cubic smoothing spline):

```{r conf_int_simple_ex}
# check the critical values
alpha <- .05
crit_val <- qchisq(1 - alpha, 1)

# fit the cubic smoothing spline
pls <- -sapply(pl_curve_res, function(x) x$opt_out$value)
smooth_est <- smooth.spline(sigs, pls)

# check that we have values within the bounds
max_ml <- -opt_out$value
ll_diffs <- 2 * (max_ml - pls)
stopifnot(any(head(ll_diffs, length(ll_diffs) / 2) > crit_val), 
          any(tail(ll_diffs, length(ll_diffs) / 2) > crit_val))

# find the values
max_par <- tail(opt_out$par, 1)
lb <- uniroot(function(x) 2 * (max_ml - predict(smooth_est, x)$y) - crit_val, 
              c(min(sigs)       , exp(max_par / 2)))$root
ub <- uniroot(function(x) 2 * (max_ml - predict(smooth_est, x)$y) - crit_val, 
              c(exp(max_par / 2), max(sigs)))$root

# the confidence interval 
c(lb, ub)
c(lb, ub)^2 # on the variance scale
```

A caveat is that issues with the $\chi^2$ approximation may arise on the 
boundary of the scale parameter ($\sigma = 0$; 
see https://stats.stackexchange.com/a/4894/81865).
Notice that the above may fail if the estimated profile likelihood is not 
smooth e.g. because of convergence issues. We can plot the profile likelihood 
and highlight the critical value as follows:

```{r plot_simple_ex_profile_likelihood}
par(mar = c(5, 5, 1, 1))
plot(sigs, pls, bty = "l",
     pch = 16, xlab = expression(sigma), ylab = "Profile likelihood")
grid()
lines(predict(smooth_est, seq(min(sigs), max(sigs), length.out = 100)))
abline(v = exp(tail(opt_out$par, 1) / 2), lty = 2) # the estimate
abline(v = sqrt(attr(dat, "sig_sq")), lty = 3) # the true value
abline(v = lb, lty = 3) # mark the lower bound
abline(v = ub, lty = 3) # mark the upper bound
abline(h = max_ml - crit_val / 2, lty = 3) # mark the critical value
```

We only ran the above with one seed. We can draw the curve with using different
seeds to check if this does not change the estimates.  We will likely need to 
use more samples if the result depends on the seed.

```{r simple_ex_more_profile_likelihood, cache = 1}
seeds <- 1:4
seeds_n_sigs <- expand.grid(seed = seeds, sig = sigs)

ll_terms <- get_pedigree_ll_terms(dat, max_threads = 4L)
pl_curve_res <- Map(function(sig, seed){
  # set the parameters to pass
  beta <- start$beta_no_rng
  sig_sq_log <- 2 * log(sig)
  beta_scaled <- beta * sqrt(1 + sig^2)
  
  # optimize like before but using the fix argument
  opt_out_quick <- pedmod_opt(
    ptr = ll_terms, par = c(beta_scaled, sig_sq_log), maxvls = 1000L, 
    abs_eps = 0, rel_eps = 1e-2, minvls = 100L, use_aprx = TRUE, n_threads = 4L, 
    fix = length(beta) + 1L, seed = seed)
  opt_out <- pedmod_opt(
    ptr = ll_terms, par = c(opt_out_quick$par, sig_sq_log), abs_eps = 0, 
    use_aprx = TRUE, n_threads = 4L, fix = length(beta) + 1L, seed = seed,
    # we changed the parameters
    maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L)
  
  # report to console and return
  message(sprintf("\nLog-likelihood %.5f (%.5f). Estimated parameters:", 
                  -opt_out$value, -opt_out_quick$value))
  message(paste0(capture.output(print(
    c(opt_out$par, Scale = sig))), collapse = "\n"))
  
  list(opt_out_quick = opt_out_quick, opt_out = opt_out)
}, sig = seeds_n_sigs$sig, seed = seeds_n_sigs$seed)
```

The different profile likelihood curves are drawn below:

```{r draw_mult_pf_curves}
# plot the profile likelihood values
pls <- -sapply(pl_curve_res, function(x) x$opt_out$value)
pls <- matrix(pls, length(seeds), dimnames = list(seeds, sigs))
matplot(sigs, t(pls), pch = seq_along(seeds) + 15L, bty = "l", col = "black", 
        xlab = expression(sigma), ylab = "Profile likelihood")
grid()
# plot the difference from the mean
matplot(sigs, t(pls) - colMeans(pls), pch = seq_along(seeds) + 15L, bty = "l", 
        col = "black", xlab = expression(sigma), 
        ylab = "Diff. profile likelihood")
grid()
```

We make a small simulation study below where we are interested in the estimation 
time and bias.

```{r clean_pre_sim_study_simple, echo = FALSE}
rm(list = setdiff(ls(), c("sim_dat", "ped", "fam")))
```

```{r sim_study_simple}
# the seeds we will use
seeds <- c(36451989L, 18774630L, 76585289L, 31898455L, 55733878L, 99681114L, 37725150L, 99188448L, 66989159L, 20673587L, 47985954L, 42571905L, 53089211L, 18457743L, 96049437L, 70222325L, 86393368L, 45380572L, 81116968L, 48291155L, 89755299L, 69891073L, 1846862L, 15263013L, 37537710L, 
           25194071L, 14471551L, 38278606L, 55596031L, 5436537L, 75008107L, 83382936L, 50689482L, 71708788L, 52258337L, 23423931L, 61069524L, 24452554L, 32406673L, 14900280L, 24818537L, 59733700L, 82407492L, 95500692L, 62528680L, 88728797L, 9891891L, 36354594L, 69630736L, 41755287L)

# run the simulation study
sim_study <- lapply(seeds, function(s){
  set.seed(s)
  
  # only run the result if it has not been computed
  f <- file.path("cache", "sim_study_simple", paste0("simple-", s, ".RDS"))
  if(!file.exists(f)){
    # simulate the data
    dat <- sim_dat(n_fams = 400L)
    
    # get the starting values
    library(pedmod)
    ll_terms <- get_pedigree_ll_terms(dat, max_threads = 4L)
    ti_start <- system.time(start <- pedmod_start(
      ptr = ll_terms, data = dat, n_threads = 4L))
    start$time <- ti_start
    
    ti_fit <- system.time(
      opt_out <- pedmod_opt(
        ptr = ll_terms, par = start$par, abs_eps = 0, use_aprx = TRUE, 
        n_threads = 4L, 
        maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L))
    opt_out$time <- ti_fit
    
    out <- list(start = start, opt_out = opt_out, 
                ll_no_rng = start$logLik_no_rng)
    saveRDS(out, f)
  }
  
  # report to console and return 
  out <- readRDS(f)
  message(paste0(capture.output(out$opt_out$par), collapse = "\n"))
  
  out
})

# gather the estimates
beta_est <- sapply(sim_study, function(x) head(x$opt_out$par, 3))
sigma_est <- sapply(sim_study, function(x) exp(tail(x$opt_out$par, 1) / 2))

# compute the errors
tmp <- sim_dat(2L)
err <- rbind(beta_est, sigma = sigma_est) - 
  c(attr(tmp, "beta"), sqrt(attr(tmp, "sig_sq")))

# get the bias estimates and the standard errors
rbind(Bias = rowMeans(err), 
      SE   = apply(err, 1, sd) / sqrt(NCOL(err)))

# make a box plot
par(mar = c(5, 5, 1, 1))
boxplot(t(err), ylab = "Error")
abline(h = 0, lty = 2)
grid()
# get the average computation times
time_vals <- sapply(sim_study, function(x) {
  keep <- c("opt_out", "start")
  out <- setNames(sapply(x[keep], function(z) z$time["elapsed"]), keep)
  c(out, total = sum(out))
})
summary(t(time_vals))
```

### Adding Environmental Effects 

```{r clean_pre_simple_w_ev, echo = FALSE}
rm(list = setdiff(ls(), c("ped", "fam")))
```

As an extension, we can add an environmental effect. The new scale matrix, 
the $C_{i2}$'s, can be written as:

```{r xtra_mat_simple_w_ev}
C_env <- matrix(0., NROW(fam), NROW(fam))
C_env[c(1:3, 5)   , c(1:3, 5)   ] <- 1
C_env[c(3:4, 7:8) , c(3:4, 7:8) ] <- 1
C_env[c(5:6, 9:10), c(5:6, 9:10)] <- 1

Matrix::Matrix(C_env, sparse = TRUE)
```

We assign the new simulation function below but this time we include only 
binary covariates:

```{r simple_w_ev_assign_sim_dat}
# simulates a data set. 
# 
# Args:
#   n_fams: number of families.
#   beta: the fixed effect coefficients.
#   sig_sq: the scale parameters.
sim_dat <- function(n_fams, beta = c(-3, 4), sig_sq = c(2, 1)){
  # setup before the simulations
  Cmat <- 2 * kinship(ped)
  n_obs <- NROW(fam)
  Sig <- diag(n_obs) + sig_sq[1] * Cmat + sig_sq[2] * C_env
  Sig_chol <- chol(Sig)
  
  # simulate the data
  out <- replicate(
    n_fams, {
      # simulate covariates
      X <- cbind(`(Intercept)` = 1, Binary = runif(n_obs) > .9)
      
      # assign the linear predictor + noise
      eta <- drop(X %*% beta) + drop(rnorm(n_obs) %*% Sig_chol)
      
      # return the list in the format needed for the package
      list(y = as.numeric(eta > 0), X = X, scale_mats = list(
        Genetic = Cmat, Environment = C_env))
    }, simplify = FALSE)
  
  # add attributes with the true values and return 
  attributes(out) <- list(beta = beta, sig_sq = sig_sq)
  out
}
```

The model is 

$$\begin{align*}
 Y_{ij} &= \begin{cases} 1 & \beta_0 + \beta_1 B_{ij} + E_{ij} + G_{ij} + R_{ij} > 0 \\ 0 & \text{otherwise} \end{cases} \\
 X_{ij} &\sim N(0, 1) \\
 B_{ij} &\sim \text{Bin}(0.5, 1) \\
 (G_{i1}, \dots G_{in_{i}})^\top &\sim N^{(n_i)}(\vec 0, \sigma^2_G C_{i1}) \\
(E_{i1}, \dots E_{in_{i}})^\top &\sim N^{(n_i)}(\vec 0, \sigma^2_E C_{i2}) \\
 R_{ij} &\sim N(0, 1)\end{align*}$$
 
where $C_{i1}$ is two times the kinship matrix, $C_{i2}$ is singular matrix
for the environment effect, and 
$B_{ij}$ is an observed covariate.
In this case, we exploit that some of log marginal likelihood terms are 
identical. That is, some of the combinations of pedigrees, covariates, and 
outcomes match. Therefor, we can use the `cluster_weights` arguments to reduce 
the computation time:

```{r simple_w_ev_sim, cache = 1}
# simulate a data set
set.seed(27107390)
dat <- sim_dat(n_fams = 1000L)

# compute the log marginal likelihood by not using that some of the log marginal 
# likelihood terms are identical
beta_true   <- attr(dat, "beta")
sig_sq_true <- attr(dat, "sig_sq")

library(pedmod)
ll_terms <- get_pedigree_ll_terms(dat, max_threads = 4L)
system.time(ll_res <- eval_pedigree_ll(
  ll_terms, c(beta_true, log(sig_sq_true)), maxvls = 100000L, abs_eps = 0, 
  rel_eps = 1e-3, minvls = 2500L, use_aprx = TRUE, n_threads = 4))
system.time(grad_res <- eval_pedigree_grad(
  ll_terms, c(beta_true, log(sig_sq_true)), maxvls = 100000L, abs_eps = 0, 
  rel_eps = 1e-3, minvls = 2500L, use_aprx = TRUE, n_threads = 4))

# find the duplicated combinations of pedigrees, covariates, and outcomes. One 
# likely needs to change this code if the pedigrees are not identical but are 
# identical if they are permuted. In this case, the code below will miss 
# identical terms
dat_unqiue <- dat[!duplicated(dat)]
attributes(dat_unqiue) <- attributes(dat)
length(dat_unqiue) # number of unique terms

# get the weights. This can be written in a much more efficient way
c_weights <- sapply(dat_unqiue, function(x)
  sum(sapply(dat, identical, y = x)))

# get the C++ object and show that the computation time is reduced
ll_terms <- get_pedigree_ll_terms(dat_unqiue, max_threads = 4L)

system.time(ll_res_fast <- eval_pedigree_ll(
  ll_terms, c(beta_true, log(sig_sq_true)), maxvls = 100000L, abs_eps = 0, 
  rel_eps = 1e-3, minvls = 2500L, use_aprx = TRUE, n_threads = 4, 
  cluster_weights = c_weights))
system.time(grad_res_fast <- eval_pedigree_grad(
  ll_terms, c(beta_true, log(sig_sq_true)), maxvls = 100000L, abs_eps = 0, 
  rel_eps = 1e-3, minvls = 2500L, use_aprx = TRUE, n_threads = 4, 
  cluster_weights = c_weights))

# show that we get the same (up to a Monte Carlo error)
print(c(redundant = ll_res, fast = ll_res_fast), digits = 6)
rbind(redundant = grad_res, fast = grad_res_fast)
rm(dat) # will not need this anymore

# find the starting values
start <- pedmod_start(ptr = ll_terms, data = dat_unqiue, 
                      cluster_weights = c_weights)

# optimize
system.time(
  opt_out_quick <- pedmod_opt(
    ptr = ll_terms, par = start$par, abs_eps = 0, use_aprx = TRUE, 
    n_threads = 4L,  cluster_weights = c_weights,
    maxvls = 5000L, rel_eps = 1e-2, minvls = 500L))
system.time(
  opt_out <- pedmod_opt(
    ptr = ll_terms, par = opt_out_quick$par, abs_eps = 0, use_aprx = TRUE, 
    n_threads = 4L,  cluster_weights = c_weights,
    # we changed the parameters
    maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L))
```

The results are shown below:

```{r est_simple_w_res}
# parameter estimates versus the truth
rbind(opt_out       = head(opt_out$par, -2), 
      opt_out_quick = head(start  $par, -2), 
      truth         = attr(dat_unqiue, "beta"))
rbind(opt_out       = exp(tail(opt_out$par, 2)), 
      opt_out_quick = exp(tail(start  $par, 2)), 
      truth         = attr(dat_unqiue, "sig_sq"))

# log marginal likelihoods
print( start  $logLik_est, digits = 8)  # this is unreliably/imprecise
print(-opt_out$value     , digits = 8)
```

We can make a 2D profile likelihood curve as follows:

```{r simple_w_ev_ex_profile_likelihood, cache = 1}
# get the values at which we evaluate the profile likelihood
rg <- Map(function(est, truth)
  range(exp(est / 2) * c(.8, 1.25), truth), 
  est = tail(opt_out$par, 2), truth = sqrt(attr(dat_unqiue, "sig_sq")))

sig_vals1 <- seq(rg[[1]][1], rg[[1]][2], length.out = 5)
sig_vals2 <- seq(rg[[2]][1], rg[[2]][2], length.out = 5)
sigs <- expand.grid(sigma1 = sig_vals1,
                    sigma2 = sig_vals2)

# compute the profile likelihood
ll_terms <- get_pedigree_ll_terms(dat_unqiue, max_threads = 4L)
pl_curve_res <- Map(function(sig1, sig2){
  # set the parameters to pass
  beta <- start$beta_no_rng
  sig <- c(sig1, sig2)
  sig_sq_log <- 2 * log(sig)
  beta_scaled <- beta * sqrt(1 + sum(sig^2))
  
  # optimize like before but using the fix argument
  opt_out_quick <- pedmod_opt(
    ptr = ll_terms, par = c(beta_scaled, sig_sq_log), maxvls = 5000L, abs_eps = 0, 
    rel_eps = 1e-2, minvls = 500L, use_aprx = TRUE, n_threads = 4L, 
    fix = length(beta) + 1:2, cluster_weights = c_weights)
  
  opt_out <- pedmod_opt(
    ptr = ll_terms, par = c(opt_out_quick$par, sig_sq_log), abs_eps = 0, 
    use_aprx = TRUE, n_threads = 4L, fix = length(beta) + 1:2,
    cluster_weights = c_weights,
    # we changed the parameters
    maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L)
  
  # report to console and return
  message(sprintf("\nLog-likelihood %.5f (%.5f). Estimated parameters:", 
                  -opt_out$value, -opt_out_quick$value))
  message(paste0(capture.output(print(
    c(opt_out$par, Scale = sig))), collapse = "\n"))
  
  list(opt_out_quick = opt_out_quick, opt_out = opt_out)
}, sig1 = sigs$sigma1, sig2 = sigs$sigma2)
```

```{r draw_simple_w_ev_ex_profile_likelihood}
par(mfcol = c(2, 2), mar = c(1, 1, 1, 1))
pls <- -sapply(pl_curve_res, function(x) x$opt_out$value)
for(i in 1:3 - 1L)
  persp(sig_vals1, sig_vals2, matrix(pls, length(sig_vals1)), 
        xlab = "\nGenetic", ylab = "\nEnvironment", 
        zlab = "\n\nProfile likelihood", theta = 65 + i * 90, 
        ticktype = "detailed")
```

We make a small simulation study below where we are interested in the estimation 
time and bias.

```{r clean_pre_sim_simple_w_ev, echo = FALSE}
rm(list = setdiff(ls(), c("sim_dat", "ped", "fam", "C_env")))
```

```{r sim_study_simple_w}
# the seeds we will use
seeds <- c(36451989L, 18774630L, 76585289L, 31898455L, 55733878L, 99681114L, 37725150L, 99188448L, 66989159L, 20673587L, 47985954L, 42571905L, 53089211L, 18457743L, 96049437L, 70222325L, 86393368L, 45380572L, 81116968L, 48291155L, 89755299L, 69891073L, 1846862L, 15263013L, 37537710L, 
           25194071L, 14471551L, 38278606L, 55596031L, 5436537L, 75008107L, 83382936L, 50689482L, 71708788L, 52258337L, 23423931L, 61069524L, 24452554L, 32406673L, 14900280L, 24818537L, 59733700L, 82407492L, 95500692L, 62528680L, 88728797L, 9891891L, 36354594L, 69630736L, 41755287L)

# run the simulation study
sim_study <- lapply(seeds, function(s){
  set.seed(s)
  
  # only run the result if it has not been computed
  f <- file.path("cache", "sim_study_simple_w_env", 
                 paste0("simple-", s, ".RDS"))
  if(!file.exists(f)){
    # simulate the data
    dat <- sim_dat(n_fams = 1000L)
    
    # get the weighted data set
    dat_unqiue <- dat[!duplicated(dat)]
    attributes(dat_unqiue) <- attributes(dat)
    c_weights <- sapply(dat_unqiue, function(x)
      sum(sapply(dat, identical, y = x)))
    rm(dat)
    
    # get the starting values
    library(pedmod)
    ll_terms <- get_pedigree_ll_terms(dat_unqiue, max_threads = 4L)
    ti_start <- system.time(start <- pedmod_start(
      ptr = ll_terms, data = dat_unqiue, n_threads = 4L, 
      cluster_weights = c_weights))
    start$time <- ti_start
    
    # fit the model
    ti_quick <- system.time(
      opt_out_quick <- pedmod_opt(
        ptr = ll_terms, par = start$par, maxvls = 5000L, abs_eps = 0, 
        rel_eps = 1e-2, minvls = 500L, use_aprx = TRUE, n_threads = 4L, 
        cluster_weights = c_weights))
    opt_out_quick$time <- ti_quick
    
    ti_slow <- system.time(
      opt_out <- pedmod_opt(
        ptr = ll_terms, par = opt_out_quick$par, abs_eps = 0, use_aprx = TRUE, 
        n_threads = 4L, cluster_weights = c_weights,
        # we changed the parameters
        maxvls = 25000L, rel_eps = 1e-3, minvls = 5000L))
    opt_out$time <- ti_slow
    
    out <- list(start = start, opt_out = opt_out, opt_out_quick = opt_out_quick, 
                opt_out = opt_out, ll_no_rng = start$logLik_no_rng)
    saveRDS(out, f)
  }
  
  # report to console and return 
  out <- readRDS(f)
  message(paste0(capture.output(out$opt_out$par), collapse = "\n"))
  
  out
})

# gather the estimates
tmp <- sim_dat(2L)
beta_est <- sapply(sim_study, function(x) head(x$opt_out$par, 2))
sigma_est <- sapply(sim_study, function(x) exp(tail(x$opt_out$par, 2) / 2))
rownames(sigma_est) <- names(tmp[[1L]]$scale_mats)

# compute the errors
err <- rbind(beta_est, sigma_est) - 
  c(attr(tmp, "beta"), sqrt(attr(tmp, "sig_sq")))

# get the bias estimates and the standard errors
rbind(Bias = rowMeans(err), 
      SE   = apply(err, 1, sd) / sqrt(NCOL(err)))

# make a box plot
par(mar = c(5, 5, 1, 1))
boxplot(t(err), ylab = "Error")
abline(h = 0, lty = 2)
grid()
# get the average computation times
time_vals <- sapply(sim_study, function(x) {
  keep <- c("opt_out", "opt_out_quick", "start")
  out <- setNames(sapply(x[keep], function(z) z$time["elapsed"]), keep)
  c(out, total = sum(out))
})
summary(t(time_vals))
```

### More Complicated Example

```{r clean_up_complicated, echo = FALSE}
rm(list = ls())
```

We consider a more complicated example in this section and use some of the lower
level functions in the package as an example.
We start by sourcing a file to get a function to simulate a data set with 
a maternal effect and a genetic effect like in @Mahjani20:

```{r source_sim_file}
# source the file to get the simulation function
source(system.file("gen-pedigree-data.R", package = "pedmod"))

# simulate a data set
set.seed(68167102)
dat <- sim_pedigree_data(n_families = 1000L)

# distribution of family sizes
par(mar = c(5, 4, 1, 1))
plot(table(sapply(dat$sim_data, function(x) length(x$y))), 
     xlab = "Family size", ylab = "Number of families", bty = "l")
# total number of observations
sum(sapply(dat$sim_data, function(x) length(x$y)))

# average event rate
mean(unlist(sapply(dat$sim_data, `[[`, "y")))
```

As @Mahjani20, we have data families linked by three generations but we 
only have data for the last generation. We illustrate this with the first 
family in the simulated data set:

```{r one_family}
# this is the full family 
library(kinship2)
fam1 <- dat$sim_data[[1L]]
plot(fam1$pedAll)
# here is the C matrix for the genetic effect
rev_img <- function(x, ...)
  image(x[, NROW(x):1], ...)
cl <- colorRampPalette(c("Red", "White", "Blue"))(101)

par(mar = c(2, 2, 1, 1))
rev_img(fam1$rel_mat, xaxt = "n", yaxt = "n", col = cl, 
        zlim = c(-1, 1))
# the first part of the matrix is given below
with(fam1, rel_mat[seq_len(min(10, NROW(rel_mat))), 
                   seq_len(min(10, NROW(rel_mat)))])

# here is the C matrix for the maternal effect
rev_img(fam1$met_mat, xaxt = "n", yaxt = "n", col = cl, 
        zlim = c(-1, 1))
# each simulated family has such two matrices in addition to a design matrix
# for the fixed effects, X, and a vector with outcomes, y
str(fam1[c("X", "y")])
```

Then we perform the model estimation:

<!-- knitr::opts_knit$set(output.dir = ".") -->
<!-- knitr::load_cache("est_mod", path = "cache/README-") -->

```{r est_mod, cache=1}
# the true parameters are
dat$beta
dat$sc # the sigmas squared

# prepare the data to pass to the functions in the package
dat_arg <- lapply(dat$sim_data, function(x){
  # we need the following for each family: 
  #   y: the zero-one outcomes.
  #   X: the design matrix for the fixed effects. 
  #   scale_mats: list with the scale matrices for each type of effect.
  list(y = as.numeric(x$y), X = x$X,
       scale_mats = list(x$rel_mat, x$met_mat))
})

# create a C++ object
library(pedmod)
ll_terms <- get_pedigree_ll_terms(dat_arg, max_threads = 4L)

# get the starting values. This is very fast
y <- unlist(lapply(dat_arg, `[[`, "y"))
X <- do.call(rbind, lapply(dat_arg, `[[`, "X"))
start_fit <-  glm.fit(X, y, family = binomial("probit"))

# log-likelihood at the starting values without random effects
-sum(start_fit$deviance) / 2     
(beta <- start_fit$coefficients) # starting values for fixed effects 

# start at moderate sized scale parameters
sc <- rep(log(.2), 2)

# check log likelihood at the starting values. First we assign a function 
# to approximate the log likelihood and the gradient
fn <- function(par, seed = 1L, rel_eps = 1e-2, use_aprx = TRUE, 
               n_threads = 4L, indices = NULL, maxvls = 25000L){
  set.seed(seed)
  -eval_pedigree_ll(
    ll_terms, par = par, maxvls = maxvls, abs_eps = 0, rel_eps = rel_eps, 
    minvls = 1000L, use_aprx = use_aprx, n_threads = n_threads, 
    indices = indices)
}
gr <- function(par, seed = 1L, rel_eps = 1e-2, use_aprx = TRUE, 
               n_threads = 4L, indices = NULL, maxvls = 25000L){
  set.seed(seed)
  out <- -eval_pedigree_grad(
    ll_terms, par = par, maxvls = maxvls, abs_eps = 0, rel_eps = rel_eps, 
    minvls = 1000L, use_aprx = use_aprx, n_threads = n_threads, 
    indices = indices)
  structure(c(out), value = -attr(out, "logLik"), 
            n_fails = attr(out, "n_fails"))
}

# check output at the starting values
system.time(ll <- -fn(c(beta, sc)))
ll # the log likelihood at the starting values
system.time(gr_val <- gr(c(beta, sc)))
gr_val # the gradient at the starting values

# standard deviation of the approximation
sd(sapply(1:25, function(seed) fn(c(beta, sc), seed = seed)))

# we do the same for the gradient elements but only for a subset of the 
# log marginal likelihood elements
gr_hats <- sapply(1:25, function(seed) gr(c(beta, sc), seed = seed, 
                                          indices = 0:99))
apply(gr_hats, 1, sd)

# verify the gradient (may not be exactly equal due to MC error)
rbind(numDeriv = numDeriv::grad(fn, c(beta, sc), indices = 0:10), 
      pedmod   = gr(c(beta, sc), indices = 0:10))

# optimize the log likelihood approximation
system.time(opt <- optim(c(beta, sc), fn, gr, method = "BFGS"))
```

The output from the optimization is shown below:

```{r show_est_mod}
print(-opt$value, digits = 8) # the maximum log likelihood
opt$convergence               # check convergence

# compare the estimated fixed effects with the true values
rbind(truth     = dat$beta, 
      estimated = head(opt$par, length(dat$beta)))

# compare estimated scale parameters with the true values
rbind(truth     = dat$sc, 
      estimated = exp(tail(opt$par, length(dat$sc))))
```

```{r svrg, eval = FALSE, echo = FALSE}
#####
# performs stochastic gradient descent instead (using SVRG).
#
# Args:
#   par: starting value.
#   gr: gradient function which return the function value as an attributate
#       called value.
#   n_clust: number of clusters.
#   batch_size: number of observations in each batch.
#   maxit: maximum number of iteration.
#   lr: learning rate.
#   verbose: print output during the estimation.
#   decay: numeric scalar used to decrease the learning rate.
#   ...: arguments passed to gr.
svrg <- function(par, gr, n_clust, batch_size, maxit = 10L, 
                 lr, verbose = FALSE, decay = .98, ...){
  indices <- sample.int(n_clust, replace = FALSE) - 1L
  blocks <- tapply(indices, (seq_along(indices) - 1L) %/% batch_size,
                   identity, simplify = FALSE)

  n_blocks <- length(blocks)
  n_par <- length(par)
  estimates <- matrix(NA_real_, n_par, maxit + 1L)
  fun_vals <- numeric(maxit + 1L)
  estimates[, 1L] <- par

  lr_use <- lr / decay
  V_mult <- qnorm(1 - .99 / maxit)
  for(k in 1:maxit + 1L){
    old_val <- estimates[, k - 1L]
    old_grs <- sapply(1:n_blocks - 1L, function(ii){
      idx_b <- (ii %% n_blocks) + 1L
      res_old <- gr(old_val, indices = blocks[[idx_b]], ...)
      c(attr(res_old, "value"), res_old)
    })

    fun_vals[k - 1L] <- sum(old_grs[1, ])
    old_grs <- old_grs[-1L, , drop = FALSE ]
    old_gr <- rowSums(old_grs) / n_blocks

    lr_use <- lr_use * decay
    for(ii in 1:n_blocks - 1L){
      idx_b <- (ii %% n_blocks) + 1L
      res <- gr(par, indices = blocks[[idx_b]], ...)
      fun_vals[k] <- fun_vals[k] + attr(res, "value")
      dir <- res - old_grs[, ii + 1L] + old_gr

      par <- par - lr_use * dir
    }

    estimates[, k] <- par

    if(verbose)
      cat(
        sprintf("End if iteration %4d with learning rate %.8f", k - 1L,
                lr_use),
        sprintf("Log marginal likelihood approximation is %12.2f", fun_vals[k]),
        sprintf("Previous approximate gradient norm was %14.2f\n",
                n_blocks * norm(as.matrix(old_gr))),
        sep = "\n")

    old_v <- fun_vals[k - 1L]
    new_v <- fun_vals[k]
  }

  list(result = par, fun_vals = fun_vals[2:k],
       estimates = estimates[, 2:k, drop = FALSE])
}

set.seed(1)
svrg_res <- svrg(c(beta, sc), gr = gr, n_clust = length(dat_arg), 
                 batch_size = 200L, lr = 2e-3, verbose = TRUE, maxit = 50L)
```

### Computation in Parallel

```{r pre_comp_par, echo = FALSE}
library(pedmod)
ll_terms <- get_pedigree_ll_terms(dat_arg, max_threads = 4L)
```

The method scales reasonably well in the number of threads as 
shown below:

```{r time_mult, cache = 1}
library(microbenchmark)
microbenchmark(
  `fn (1 thread)`  = fn(c(beta, sc), n_threads = 1),
  `fn (2 threads)` = fn(c(beta, sc), n_threads = 2),
  `fn (4 threads)` = fn(c(beta, sc), n_threads = 4),
  `gr (1 thread)`  = gr(c(beta, sc), n_threads = 1),
  `gr (2 threads)` = gr(c(beta, sc), n_threads = 2),
  `gr (4 threads)` = gr(c(beta, sc), n_threads = 4),
  times = 1)
```

### Using ADAM
We use stochastic gradient descent with the ADAM method [@Kingma15] in 
this section. We define a function below to apply ADAM and use it 
to estimate the model.

<!-- knitr::opts_knit$set(output.dir = ".") -->
<!-- knitr::load_cache("use_adam", path = "cache/README-") -->

```{r re_create_ptr, echo = FALSE}
library(pedmod)
ll_terms <- get_pedigree_ll_terms(dat_arg, max_threads = 4L)
```

```{r use_adam, cache = 1}
#####
# performs stochastic gradient descent (using ADAM).
#
# Args:
#   par: starting value.
#   gr: function to evaluate the log marginal likelihood.
#   n_clust: number of observation.
#   n_blocks: number of blocks.
#   maxit: maximum number of iteration.
#   seed: seed to use.
#   epsilon, alpha, beta_1, beta_2: ADAM parameters.
#   maxvls: maximum number of samples to draw in each iteration. Thus, it 
#           needs maxit elements.
#   verbose: print output during the estimation.
#   ...: arguments passed to gr.
adam <- function(par, gr, n_clust, n_blocks, maxit = 10L,
                 seed = 1L, epsilon = 1e-8, alpha = .001, beta_1 = .9,
                 beta_2 = .999, maxvls = rep(10000L, maxit), 
                 verbose = FALSE, ...){
  grp_dummy <- (seq_len(n_clust) - 1L) %% n_blocks
  n_par <- length(par)
  m <- v <- numeric(n_par)
  fun_vals <- numeric(maxit)
  estimates <- matrix(NA_real_, n_par, maxit)
  i <- -1L

  for(k in 1:maxit){
    # sample groups
    indices <- sample.int(n_clust, replace = FALSE) - 1L
    blocks <- tapply(indices, grp_dummy, identity, simplify = FALSE)
    
    for(ii in 1:n_blocks){
      i <- i + 1L
      idx_b <- (i %% n_blocks) + 1L
      m_old <- m
      v_old <- v
      res <- gr(par, indices = blocks[[idx_b]], maxvls = maxvls[k])
      fun_vals[(i %/% n_blocks) + 1L] <-
        fun_vals[(i %/% n_blocks) + 1L] + attr(res, "value")
      res <- c(res)

      m <- beta_1 * m_old + (1 - beta_1) * res
      v <- beta_2 * v_old + (1 - beta_2) * res^2

      m_hat <- m / (1 - beta_1^(i + 1))
      v_hat <- v / (1 - beta_2^(i + 1))

      par <- par - alpha * m_hat / (sqrt(v_hat) + epsilon)
    }
    
    if(verbose){
      cat(sprintf("Ended iteration %4d. Running estimate of the function value is: %14.2f\n", 
                  k, fun_vals[k]))
      cat("Parameter estimates are:\n")
      cat(capture.output(print(par)), sep = "\n")
      cat("\n")
    }

    estimates[, k] <- par
  }

  list(par = par, estimates = estimates, fun_vals = fun_vals)
}

#####
# use the function
# assign the maximum number of samples we will use
maxit <- 100L
minvls <- 250L
maxpts <- formals(gr)$maxvls
maxpts_use <- exp(seq(log(2 * minvls), log(maxpts), length.out = maxit))

# show the maximum number of samples we use
par(mar = c(5, 4, 1, 1))
plot(maxpts_use, pch = 16, xlab = "Iteration number", bty = "l",
     ylab = "Maximum number of samples", ylim = range(0, maxpts_use))
set.seed(1)
system.time(
  adam_res <- adam(c(beta, sc), gr = gr, n_clust = length(dat_arg), 
                   n_blocks = 10L, alpha = 1e-2, maxit = maxit, 
                   verbose = FALSE, maxvls = maxpts_use, 
                   minvls = minvls))
```

The result is shown below.

```{r adam_re_create_ptr, echo = FALSE}
library(pedmod)
ll_terms <- get_pedigree_ll_terms(dat_arg, max_threads = 4L)
```

```{r res_adam}
print(-fn(adam_res$par), digits = 8) # the maximum log likelihood

# compare the estimated fixed effects with the true values
rbind(truth             = dat$beta,
      `estimated optim` = head(opt$par     , length(dat$beta)),
      `estimated ADAM`  = head(adam_res$par, length(dat$beta)))

# compare estimated scale parameters with the true values
rbind(truth             = dat$sc, 
      `estimated optim` = exp(tail(opt$par     , length(dat$sc))), 
      `estimated ADAM`  = exp(tail(adam_res$par, length(dat$sc))))

# could possibly have stopped much earlier maybe. Dashed lines are final 
# estimates
par(mar = c(5, 4, 1, 1))
matplot(t(adam_res$estimates), type = "l", col = "Black", lty = 1, 
        bty = "l", xlab = "Iteration", ylab = "Estimate")
for(s in adam_res$par)
  abline(h = s, lty = 2)
```

### The Multivariate Normal CDF Approximation

We compare the multivariate normal CDF approximation in this section 
with the approximation from the mvtnorm package which uses the implementation 
by @Genz02. The same algorithm is used 
but the version in this package is re-written in C++ and differs slightly.
Moreover, we have implemented an approximation of the standard normal CDF
and its inverse which reduces the computation time as we will show below.

```{r compare_w_mvtnorm, cache = 1}
#####
# settings for the simulation study
library(mvtnorm)
library(pedmod)
library(microbenchmark)
set.seed(78459126)
n <- 5L         # number of variables to interate out
rel_eps <- 1e-4 # the relative error to use

#####
# run the simulation study
sim_res <- replicate(expr = {
  # simulate covariance matrix and the upper bound
  S <- drop(rWishart(1L, 2 * n, diag(n) / 2 / n))
  u <- rnorm(n)
  
  # function to use pmvnorm
  use_mvtnorm <- function(rel_eps)
    pmvnorm(upper = u, sigma = S, algorithm = GenzBretz(
      abseps = 0, releps = rel_eps, maxpts = 1e7))
  
  # function to use this package
  use_mvndst <- function(use_aprx = FALSE)
    mvndst(lower = rep(-Inf, n), upper = u, mu = rep(0, n), 
           sigma = S, use_aprx = use_aprx, abs_eps = 0, rel_eps = rel_eps,
           maxvls = 1e7)

  # get a very precise estimate
  truth <- use_mvtnorm(rel_eps / 100)
  
  # computes the error with repeated approximations and compute the time it
  # takes
  n_rep <- 5L
  run_n_time <- function(expr){
    expr <- substitute(expr)
    ti <- get_nanotime()
    res <- replicate(n_rep, eval(expr))
    ti <- get_nanotime() - ti
    err <- (res - truth) / truth
    c(SE = sqrt(sum(err^2) / n_rep), time = ti / n_rep / 1e9)
  }
  
  mvtnorm_res        <- run_n_time(use_mvtnorm(rel_eps))
  mvndst_no_aprx_res <- run_n_time(use_mvndst(FALSE))
  mvndst_w_aprx_res  <- run_n_time(use_mvndst(TRUE))
  
  # return 
  rbind(mvtnorm            = mvtnorm_res, 
        `mvndst (no aprx)` = mvndst_no_aprx_res, 
        `mvndst (w/ aprx)` = mvndst_w_aprx_res)
}, n = 100, simplify = "array")
```

They have about the same average relative error as expected:

```{r show_averge_rel_err}
rowMeans(sim_res[, "SE", ])
par(mar = c(5, 4, 1, 1))
boxplot(t(sim_res[, "SE", ]))
```

The new implementation is faster when the approximation is used:

```{r use_new_impl}
rowMeans(sim_res[, "time", ])
par(mar = c(5, 4, 1, 1))
boxplot(t(sim_res[, "time", ]))
```

## References
